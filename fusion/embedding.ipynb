{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "prefixes = ['per', 'verb', 'org', 'loc', 'adj']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_nodes(name):\n",
    "    n_trees = 0\n",
    "    for prefix in prefixes:\n",
    "        with open(name + prefix + '/topicTree.nodes.json', 'r') as read_file:\n",
    "            j_nodes = json.load(read_file)\n",
    "        q = deque()\n",
    "        for node in j_nodes:\n",
    "            node_parent[prefix + node['id']] = ['ROOT']\n",
    "            q.append(node)\n",
    "            n_trees += 1\n",
    "\n",
    "        while len(q) > 0:\n",
    "            node = q.popleft()\n",
    "            node_id = prefix + node['id']\n",
    "            nodes[node_id] = len(nodes)\n",
    "            node_words[node_id] = node['text'].split(' ')\n",
    "            node_level[node_id] = node['data']['level']\n",
    "            node_children[node_id] = []\n",
    "            for child in node['children']:\n",
    "                node_parent[prefix + child['id']] = [node_id]\n",
    "                node_children[node_id].append(prefix + child['id'])\n",
    "                q.append(child)\n",
    "    print(n_trees, ' trees found')\n",
    "    print(len(nodes), ' topics found')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_assignments(name):\n",
    "    for prefix in prefixes:\n",
    "        with open(name + prefix + '/myAssignment.topics.json', 'r') as read_file:\n",
    "            j_nodes = json.load(read_file)\n",
    "        for node in j_nodes:\n",
    "            topic = node['topic']\n",
    "            assignments[prefix + topic] = {}\n",
    "            for doc in node['doc']:\n",
    "                assignments[prefix + topic][int(doc[0])] = doc[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_data_files(name):\n",
    "    cnt = 0\n",
    "    with open(name + 'myData.files.txt', 'r') as read_file:\n",
    "        tmp = read_file.read().split('\\n')\n",
    "    for i in tmp:\n",
    "        if len(i) == 0:\n",
    "            continue\n",
    "        data_files[cnt] = i\n",
    "        cnt += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load_words(name):\n",
    "    repeated = {}\n",
    "    for prefix in prefixes:\n",
    "        with open(name + prefix + '/myData.dict.csv', 'r') as read_file:\n",
    "            for tfidf in csv.reader(read_file):\n",
    "                if tfidf[3] != 'tfidf':\n",
    "                    if tfidf[0] not in words_dic:\n",
    "                        words_dic[tfidf[0]] = len(words_dic)\n",
    "                        tf_idf[tfidf[0]] = float(tfidf[3])\n",
    "                    else:\n",
    "                        if tfidf[0] not in repeated:\n",
    "                            repeated[tfidf[0]] = 2\n",
    "                        else:\n",
    "                            repeated[tfidf[0]] += 1\n",
    "                        tf_idf[tfidf[0]] += float(tfidf[3])\n",
    "    for word in repeated:\n",
    "        tf_idf[word] /= repeated[word]\n",
    "    print(len(repeated), 'repeated words')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def load_sparse(name):\n",
    "    with open(name + '/myData.sparse.txt', 'r') as read_file:\n",
    "        doc_words = read_file.read().split('\\n')\n",
    "    for i in data_files:\n",
    "        sparse[i] = []\n",
    "    for i in doc_words:\n",
    "        if len(i) == 0:\n",
    "            continue\n",
    "        tmp = i.split(\", \")\n",
    "        tmp[0] = int(tmp[0])\n",
    "        sparse[tmp[0]].append(tmp[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def read_java_bayes(name):\n",
    "    for node in nodes:\n",
    "        words_prop[node] = {}\n",
    "    for prefix in prefixes:\n",
    "        with open(name + prefix + '/myModel.bif', 'r') as f:\n",
    "            for i in f:\n",
    "                if i.count('|') == 0:\n",
    "                    continue\n",
    "                if i.startswith('probability ( '):\n",
    "                    a = i[i.index('\"') + 1: i.index('|') - 2]\n",
    "                    b = prefix + i[i.index('|') + 3: i.index(')') - 2]\n",
    "                    prob = float(f.readline().split(' ')[1])\n",
    "                    if a.startswith('Z'):\n",
    "                        if b not in node_prob:\n",
    "                            node_prob[b] = {}\n",
    "                        a = prefix + a\n",
    "                        node_prob[b][a] = prob\n",
    "                    else:\n",
    "                        if a in words_dic:\n",
    "                            words_prop[b][a] = prob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def prob_dfs(node):\n",
    "    for child in node_children[node]:\n",
    "        words = prob_dfs(child)\n",
    "        for word in words:\n",
    "            words_prop[node][word] = node_prob[node][child] * words_prop[child][word]\n",
    "    return words_prop[node]\n",
    "\n",
    "def get_words_prop(name):\n",
    "    read_java_bayes(name)\n",
    "    for node in nodes:\n",
    "        if len(node_parent[node]) == 1 and node_parent[node][0] == 'ROOT':\n",
    "            prob_dfs(node)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def save_np(folder, matrix, view_id):\n",
    "    m_min = matrix.min()\n",
    "    m_max = matrix.max()\n",
    "    matrix -= m_min\n",
    "    matrix /= (m_max - m_min)\n",
    "    matrix *= 2\n",
    "    matrix -= 1\n",
    "    with open(folder + view_id + \".npy\", 'wb') as f:\n",
    "        np.save(f, matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_views(name):\n",
    "    view_files = np.zeros((len(nodes), len(data_files)))\n",
    "    view_bayes = np.zeros((len(nodes), len(words_dic)))\n",
    "    view_tfidf = np.zeros((len(nodes), len(words_dic)))\n",
    "\n",
    "    for node in nodes:\n",
    "        for file in assignments[node]:\n",
    "            view_files[nodes[node]][file] = assignments[node][file]\n",
    "        for word in words_prop[node]:\n",
    "            view_bayes[nodes[node]][words_dic[word]] = words_prop[node][word]\n",
    "        for doc in assignments[node]:\n",
    "            for word in sparse[doc]:\n",
    "                if word in tf_idf:\n",
    "                    view_tfidf[nodes[node]][words_dic[word]] = tf_idf[word] * assignments[node][doc]\n",
    "\n",
    "    save_np('views/' + name, view_files, 'files')\n",
    "    save_np('views/' + name, view_bayes, 'bayes')\n",
    "    save_np('views/' + name, view_tfidf, 'tfidf')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_ids2nodes():\n",
    "    for i in nodes:\n",
    "        id2node[nodes[i]] = i\n",
    "\n",
    "def read_results(name):\n",
    "    with open(name, 'rb') as f:\n",
    "        return np.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def process_clusters(clusters):\n",
    "    d = {}\n",
    "    cnt = 0\n",
    "    for i in clusters:\n",
    "        if i in d:\n",
    "            d[i].append(cnt)\n",
    "        else:\n",
    "            d[i] = [cnt]\n",
    "        cnt += 1\n",
    "\n",
    "    cnt = 0\n",
    "    for c_id in d:\n",
    "        groups = {}\n",
    "        for i in d[c_id]:\n",
    "            name = id2node[i]\n",
    "            level = node_level[name]\n",
    "            node_group[name] = c_id\n",
    "            if level in groups:\n",
    "                groups[level].append(name)\n",
    "            else:\n",
    "                groups[level] = []\n",
    "                groups[level].append(name)\n",
    "\n",
    "        for level in groups:\n",
    "            if len(groups[level]) <= 1:\n",
    "                continue\n",
    "            s = set()\n",
    "            for node in groups[level]:\n",
    "                s.add(node_parent[node][0])\n",
    "            if len(s) == 1 and list(s)[0] != 'ROOT':\n",
    "                continue\n",
    "            u_name = 'U' + str(cnt)\n",
    "            node_parent[u_name] = []\n",
    "            node_children[u_name] = []\n",
    "            cnt += 1\n",
    "            nodes[u_name] = len(nodes)\n",
    "            node_group[u_name] = c_id\n",
    "            for node in groups[level]:\n",
    "                node_parent[node] = [u_name]\n",
    "                node_children[u_name].append(node)\n",
    "            for parent in s:\n",
    "                node_parent[u_name].append(parent)\n",
    "                if parent != 'ROOT':\n",
    "                    for node in groups[level]:\n",
    "                        if node in node_children[parent]:\n",
    "                            node_children[parent].remove(node)\n",
    "                    node_children[parent].append(u_name)\n",
    "\n",
    "            s = set()\n",
    "            node_words[u_name] = []\n",
    "            i = 0\n",
    "            while True:\n",
    "                no_more = True\n",
    "                for node in groups[level]:\n",
    "                    if len(node_words[node]) > i:\n",
    "                        no_more = False\n",
    "                        if node_words[node][i] not in s:\n",
    "                            s.add(node_words[node][i])\n",
    "                            node_words[u_name].append(node_words[node][i])\n",
    "                        for aux in node_words[node][i].split('-'):\n",
    "                            s.add(aux)\n",
    "                        if len(node_words[u_name]) >= 7:\n",
    "                            break\n",
    "                if len(node_words[u_name]) >= 7 or no_more:\n",
    "                    break\n",
    "                i += 1\n",
    "    roots = 0\n",
    "    for node in nodes:\n",
    "        if len(node_parent[node]) == 1 and node_parent[node][0] == 'ROOT':\n",
    "            roots += 1\n",
    "    print(roots, ' trees after fusion')\n",
    "    print(len(nodes), ' nodes after fusion')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def export_nodes_json(name):\n",
    "    graph = []\n",
    "    for node in nodes:\n",
    "        entry = {'id': node, 'text': ' '.join(node_words[node]), 'children': []}\n",
    "        graph.append(entry)\n",
    "    with open(name, 'w') as f:\n",
    "        json.dump(graph, f, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def create_topics_d3(name, expanded):\n",
    "    graph = {\"nodes\": {}, \"links\": []}\n",
    "    for node in nodes:\n",
    "        words = node if node.startswith('U') else node[:node.index('Z')]\n",
    "        words = words + ': ' + ' '.join(node_words[node]).replace('zzz', '_')\n",
    "        is_root = False\n",
    "        if len(node_parent[node]) == 1 and node_parent[node][0] == 'ROOT':\n",
    "            is_root = True\n",
    "        d = {\"id\":node, \"name\":words, \"group\":int(node_group[node]),\n",
    "             \"isRoot\":expanded or is_root, \"children\":node_children[node], \"expanded\":expanded}\n",
    "        graph[\"nodes\"][node] = d\n",
    "        if expanded:\n",
    "            for child in node_children:\n",
    "                 graph[\"links\"].append((dict([('id', node+'-'+child), (\"source\", node), (\"target\", child)])))\n",
    "    with open(\"graphs/d3/\" + name + '.json', \"w\") as fp:\n",
    "        json.dump(graph, fp, indent=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def create_topics_gephi(name):\n",
    "    colors = {}\n",
    "    r, g, b, rr, gr, br, cnt = 80, 70, 60, 80, 70, 60, 0\n",
    "    if len(node_group) == 0:\n",
    "        for i in nodes:\n",
    "            node_group[i] = 0\n",
    "        colors[0] = '000000'\n",
    "    else:\n",
    "        for i in node_group.values():\n",
    "            if i not in colors:\n",
    "                color = '{:02x}'.format(r) if cnt < 4 else '00'\n",
    "                color += '{:02x}'.format(g) if cnt % 2 == 0 else '00'\n",
    "                color += '{:02x}'.format(b) if 1 < cnt < 6 else '00'\n",
    "                cnt += 1\n",
    "                if cnt == 7:\n",
    "                    r = (r + rr) % 256\n",
    "                    g = (g + gr) % 256\n",
    "                    b = (b + br) % 256\n",
    "                    cnt = 0\n",
    "                colors[i] = color\n",
    "\n",
    "    graph = ['graph [ directed 1']\n",
    "    for node in nodes:\n",
    "        words = node if node.startswith('U') else node[:node.index('Z')]\n",
    "        words = words + ': ' + ' '.join(node_words[node]).replace('zzz', '_')\n",
    "        graph.append('node [')\n",
    "        graph.append('id ' + str(nodes[node]))\n",
    "        graph.append('label \"' + words + '\"')\n",
    "        graph.append('graphics [fill \"#' + colors[node_group[node]] + '\"]]')\n",
    "    for node in node_children:\n",
    "        for child in node_children[node]:\n",
    "            graph.append('edge [')\n",
    "            graph.append('source ' + str(nodes[node]))\n",
    "            graph.append('target ' + str(nodes[child]) + ' ]')\n",
    "    graph.append(']')\n",
    "    with open('graphs/gephi/' + name + '.gml', 'w') as f:\n",
    "        f.write('\\n'.join(graph))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76  trees found\n",
      "1236  topics found\n",
      "241 repeated words\n",
      "42  trees after fusion\n",
      "1374  nodes after fusion\n"
     ]
    }
   ],
   "source": [
    "nodes, words_dic, node_words = {}, {}, {}\n",
    "node_parent, node_level, node_children = {}, {}, {}\n",
    "id2node, node_group, data_files, assignments, tf_idf = {}, {}, {}, {}, {}\n",
    "node_prob, words_prop, sparse = {}, {}, {}\n",
    "load_nodes('profiles/')\n",
    "load_assignments('profiles/')\n",
    "load_data_files('profiles/adj/')\n",
    "load_words('profiles/')\n",
    "get_words_prop('profiles/')\n",
    "load_sparse('profiles/')\n",
    "# get_views('profiles/')\n",
    "get_ids2nodes()\n",
    "process_clusters(read_results('clusters/profiles/150_means.npy'))\n",
    "export_nodes_json('profiles/evaluation/150_means.nodes.json')\n",
    "create_topics_gephi('profiles_150_means')\n",
    "# create_topics_d3(\"profiles\", False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}